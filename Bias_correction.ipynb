{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansontang/miniconda3_new/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_diabetes\n",
    "#from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0 = pd.read_csv(\"df_valid.csv\").rename(columns={\"pred\": \"baseline\"}).drop(columns=[\"fold\", \"Unnamed: 0\", \"text\"])\n",
    "#df1 = pd.read_csv(\"df_valid1.csv\").rename(columns={\"pred\": \"model1\"}).drop(columns=[\"context_grp_1\",\"text_grp_1\",\"text_grp_2\",\"mentioned_groups_grp_2\", \"text\"])\n",
    "#df2 = pd.read_csv(\"df_valid2.csv\").rename(columns={\"pred\": \"model2\"}).drop(columns=[\"context_grp_1\",\"text_grp_1\",\"text_grp_2\",\"mentioned_groups_grp_2\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF = df0.merge(df1).merge(df2)\n",
    "#DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_grp_1</th>\n",
       "      <th>text_grp_1</th>\n",
       "      <th>text_grp_2</th>\n",
       "      <th>mentioned_groups_grp_2</th>\n",
       "      <th>score_map</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef2d4c2e6bbb208d</td>\n",
       "      <td>abatement</td>\n",
       "      <td>mixing core materials</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c3f2750e7540ab7</td>\n",
       "      <td>abatement</td>\n",
       "      <td>multi pollution abatement device</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfd7270f57530991</td>\n",
       "      <td>abatement</td>\n",
       "      <td>pollution abatement</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cc96541d4987b399</td>\n",
       "      <td>abatement</td>\n",
       "      <td>rent abatement</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>ede41dd2a61bb0a9</td>\n",
       "      <td>wood article</td>\n",
       "      <td>substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>B</td>\n",
       "      <td>performing operations; transporting</td>\n",
       "      <td>decorative arts</td>\n",
       "      <td>C14; G09; B29; B44; B31; B41; B05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.246721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>4f366b6369dbfbf2</td>\n",
       "      <td>wood article</td>\n",
       "      <td>timber article</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B</td>\n",
       "      <td>performing operations; transporting</td>\n",
       "      <td>decorative arts</td>\n",
       "      <td>C14; G09; B29; B44; B31; B41; B05</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>51421420985d5c93</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>B</td>\n",
       "      <td>performing operations; transporting</td>\n",
       "      <td>decorative arts</td>\n",
       "      <td>C14; G09; B29; B44; B31; B41; B05</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>8ceaa2b5c2d56250</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>B</td>\n",
       "      <td>performing operations; transporting</td>\n",
       "      <td>decorative arts</td>\n",
       "      <td>C14; G09; B29; B44; B31; B41; B05</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>c4ac9d407fb427ab</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood logs</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>B</td>\n",
       "      <td>performing operations; transporting</td>\n",
       "      <td>decorative arts</td>\n",
       "      <td>C14; G09; B29; B44; B31; B41; B05</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.605233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                            target  \\\n",
       "0      54c1e3b9184cb5b6     abatement                     forest region   \n",
       "1      ef2d4c2e6bbb208d     abatement             mixing core materials   \n",
       "2      4c3f2750e7540ab7     abatement  multi pollution abatement device   \n",
       "3      bfd7270f57530991     abatement               pollution abatement   \n",
       "4      cc96541d4987b399     abatement                    rent abatement   \n",
       "...                 ...           ...                               ...   \n",
       "36468  ede41dd2a61bb0a9  wood article                         substrate   \n",
       "36469  4f366b6369dbfbf2  wood article                    timber article   \n",
       "36470  51421420985d5c93  wood article                              wood   \n",
       "36471  8ceaa2b5c2d56250  wood article                      wood article   \n",
       "36472  c4ac9d407fb427ab  wood article                         wood logs   \n",
       "\n",
       "      context  score context_grp_1                           text_grp_1  \\\n",
       "0         A47   0.00             A                    human necessities   \n",
       "1         A47   0.25             A                    human necessities   \n",
       "2         A47   0.50             A                    human necessities   \n",
       "3         A47   0.50             A                    human necessities   \n",
       "4         A47   0.00             A                    human necessities   \n",
       "...       ...    ...           ...                                  ...   \n",
       "36468     B44   0.25             B  performing operations; transporting   \n",
       "36469     B44   0.75             B  performing operations; transporting   \n",
       "36470     B44   0.50             B  performing operations; transporting   \n",
       "36471     B44   1.00             B  performing operations; transporting   \n",
       "36472     B44   0.50             B  performing operations; transporting   \n",
       "\n",
       "                                              text_grp_2  \\\n",
       "0      furniture; domestic articles or appliances; co...   \n",
       "1      furniture; domestic articles or appliances; co...   \n",
       "2      furniture; domestic articles or appliances; co...   \n",
       "3      furniture; domestic articles or appliances; co...   \n",
       "4      furniture; domestic articles or appliances; co...   \n",
       "...                                                  ...   \n",
       "36468                                    decorative arts   \n",
       "36469                                    decorative arts   \n",
       "36470                                    decorative arts   \n",
       "36471                                    decorative arts   \n",
       "36472                                    decorative arts   \n",
       "\n",
       "                                  mentioned_groups_grp_2  score_map  fold  \\\n",
       "0      A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          0     0   \n",
       "1      A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          1     0   \n",
       "2      A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          2     0   \n",
       "3      A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          2     0   \n",
       "4      A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          0     0   \n",
       "...                                                  ...        ...   ...   \n",
       "36468                  C14; G09; B29; B44; B31; B41; B05          1     3   \n",
       "36469                  C14; G09; B29; B44; B31; B41; B05          3     3   \n",
       "36470                  C14; G09; B29; B44; B31; B41; B05          2     3   \n",
       "36471                  C14; G09; B29; B44; B31; B41; B05          4     3   \n",
       "36472                  C14; G09; B29; B44; B31; B41; B05          2     3   \n",
       "\n",
       "           pred  \n",
       "0      0.000072  \n",
       "1      0.357743  \n",
       "2      0.317667  \n",
       "3      0.418723  \n",
       "4      0.000525  \n",
       "...         ...  \n",
       "36468  0.246721  \n",
       "36469  0.999446  \n",
       "36470  0.523438  \n",
       "36471  0.999572  \n",
       "36472  0.605233  \n",
       "\n",
       "[36473 rows x 12 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_valid1.csv\").drop(columns=[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_grp_1</th>\n",
       "      <th>text_grp_1</th>\n",
       "      <th>text_grp_2</th>\n",
       "      <th>mentioned_groups_grp_2</th>\n",
       "      <th>score_map</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef2d4c2e6bbb208d</td>\n",
       "      <td>abatement</td>\n",
       "      <td>mixing core materials</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357743</td>\n",
       "      <td>0.107743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c3f2750e7540ab7</td>\n",
       "      <td>abatement</td>\n",
       "      <td>multi pollution abatement device</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317667</td>\n",
       "      <td>-0.182333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfd7270f57530991</td>\n",
       "      <td>abatement</td>\n",
       "      <td>pollution abatement</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418723</td>\n",
       "      <td>-0.081277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cc96541d4987b399</td>\n",
       "      <td>abatement</td>\n",
       "      <td>rent abatement</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "      <td>A45; B60; E03; E05; A46; B08; F16; A47; D06; B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                            target context  \\\n",
       "0  54c1e3b9184cb5b6  abatement                     forest region     A47   \n",
       "1  ef2d4c2e6bbb208d  abatement             mixing core materials     A47   \n",
       "2  4c3f2750e7540ab7  abatement  multi pollution abatement device     A47   \n",
       "3  bfd7270f57530991  abatement               pollution abatement     A47   \n",
       "4  cc96541d4987b399  abatement                    rent abatement     A47   \n",
       "\n",
       "   score context_grp_1         text_grp_1  \\\n",
       "0   0.00             A  human necessities   \n",
       "1   0.25             A  human necessities   \n",
       "2   0.50             A  human necessities   \n",
       "3   0.50             A  human necessities   \n",
       "4   0.00             A  human necessities   \n",
       "\n",
       "                                          text_grp_2  \\\n",
       "0  furniture; domestic articles or appliances; co...   \n",
       "1  furniture; domestic articles or appliances; co...   \n",
       "2  furniture; domestic articles or appliances; co...   \n",
       "3  furniture; domestic articles or appliances; co...   \n",
       "4  furniture; domestic articles or appliances; co...   \n",
       "\n",
       "                              mentioned_groups_grp_2  score_map  fold  \\\n",
       "0  A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          0     0   \n",
       "1  A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          1     0   \n",
       "2  A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          2     0   \n",
       "3  A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          2     0   \n",
       "4  A45; B60; E03; E05; A46; B08; F16; A47; D06; B...          0     0   \n",
       "\n",
       "       pred      bias  \n",
       "0  0.000072  0.000072  \n",
       "1  0.357743  0.107743  \n",
       "2  0.317667 -0.182333  \n",
       "3  0.418723 -0.081277  \n",
       "4  0.000525  0.000525  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bias\"] = df[\"pred\"] - df[\"score\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jaccard_index(df_row):\n",
    "    target_set = set(df_row[\"target\"].split())\n",
    "    anchor_set = set(df_row[\"anchor\"].split())\n",
    "    return len(anchor_set.intersection(target_set)) / len(anchor_set.union(target_set))\n",
    "\n",
    "def subset(df_row, col_a, col_b):\n",
    "    return (df_row[col_a] in df_row[col_b]) and (len(df_row[col_b]) > len(df_row[col_a]))\n",
    "\n",
    "def fuzz_ratio(df_row, col_a, col_b):\n",
    "    return fuzz.ratio(df_row[col_a], df_row[col_b]) / 100\n",
    "\n",
    "def fuzz_partial_ratio(df_row, col_a, col_b):\n",
    "    return fuzz.partial_ratio(df_row[col_a], df_row[col_b]) / 100\n",
    "\n",
    "def fuzz_token_set_ratio(df_row, col_a, col_b):\n",
    "    return fuzz.token_set_ratio(df_row[col_a], df_row[col_b]) / 100\n",
    "\n",
    "def fuzz_token_sort_ratio(df_row, col_a, col_b):\n",
    "    return fuzz.token_sort_ratio(df_row[col_a], df_row[col_b]) / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"jaccard_index\"] = df.apply(find_jaccard_index, axis=1)\n",
    "\n",
    "df[\"anchor ⊂ target\"] = df.apply(subset, args=(\"anchor\",\"target\"), axis=1)\n",
    "df[\"target ⊂ anchor\"] = df.apply(subset, args=(\"target\",\"anchor\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number_of_words\"] = df[\"target\"].str.split().apply(len).values\n",
    "\n",
    "df[\"fuzz_ratio\"] = df.apply(fuzz_ratio, args=(\"anchor\",\"target\"), axis=1)\n",
    "df[\"fuzz_partial_ratio\"] = df.apply(fuzz_partial_ratio, args=(\"anchor\",\"target\"), axis=1)\n",
    "df[\"fuzz_token_set_ratio\"] = df.apply(fuzz_token_set_ratio, args=(\"anchor\",\"target\"), axis=1)\n",
    "df[\"fuzz_token_sort_ratio\"] = df.apply(fuzz_token_sort_ratio, args=(\"anchor\",\"target\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = DF.drop(columns=[\"baseline\", \"model1\", \"model2\"])\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_grp_1</th>\n",
       "      <th>text_grp_1</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>anchor ⊂ target</th>\n",
       "      <th>target ⊂ anchor</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <th>pred</th>\n",
       "      <th>bias</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.357743</td>\n",
       "      <td>0.107743</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.317667</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.418723</td>\n",
       "      <td>-0.081277</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>human necessities</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  context_grp_1         text_grp_1  jaccard_index  anchor ⊂ target  \\\n",
       "0             A  human necessities           0.00            False   \n",
       "1             A  human necessities           0.00            False   \n",
       "2             A  human necessities           0.25             True   \n",
       "3             A  human necessities           0.50             True   \n",
       "4             A  human necessities           0.50             True   \n",
       "\n",
       "   target ⊂ anchor  number_of_words  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0            False                2        0.27                0.35   \n",
       "1            False                3        0.20                0.33   \n",
       "2            False                4        0.44                1.00   \n",
       "3            False                2        0.64                1.00   \n",
       "4            False                2        0.78                1.00   \n",
       "\n",
       "   fuzz_token_set_ratio  fuzz_token_sort_ratio      pred      bias  score  \n",
       "0                  0.27                   0.27  0.000072  0.000072   0.00  \n",
       "1                  0.33                   0.33  0.357743  0.107743   0.25  \n",
       "2                  1.00                   0.44  0.317667 -0.182333   0.50  \n",
       "3                  1.00                   0.64  0.418723 -0.081277   0.50  \n",
       "4                  1.00                   0.78  0.000525  0.000525   0.00  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"context_grp_1\", \"text_grp_1\", \"jaccard_index\", \"anchor ⊂ target\", \"target ⊂ anchor\", \"number_of_words\",\n",
    "    \"fuzz_ratio\", \"fuzz_partial_ratio\", \"fuzz_token_set_ratio\", \"fuzz_token_sort_ratio\", \"pred\", \"bias\", \"score\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>anchor ⊂ target</th>\n",
       "      <th>target ⊂ anchor</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <th>pred</th>\n",
       "      <th>bias</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jaccard_index</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359760</td>\n",
       "      <td>0.249074</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.727435</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.756981</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.391743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor ⊂ target</th>\n",
       "      <td>0.359760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047205</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>0.406478</td>\n",
       "      <td>0.360223</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>0.184482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target ⊂ anchor</th>\n",
       "      <td>0.249074</td>\n",
       "      <td>-0.047205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.228518</td>\n",
       "      <td>0.163665</td>\n",
       "      <td>0.372660</td>\n",
       "      <td>0.321515</td>\n",
       "      <td>0.165649</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>0.105758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_words</th>\n",
       "      <td>0.275053</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>-0.228518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>0.171080</td>\n",
       "      <td>0.255549</td>\n",
       "      <td>0.260270</td>\n",
       "      <td>0.167878</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>0.160902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>0.163665</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>0.876469</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.481134</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.439256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <td>0.727435</td>\n",
       "      <td>0.406478</td>\n",
       "      <td>0.372660</td>\n",
       "      <td>0.171080</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.423606</td>\n",
       "      <td>0.019903</td>\n",
       "      <td>0.383781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.360223</td>\n",
       "      <td>0.321515</td>\n",
       "      <td>0.255549</td>\n",
       "      <td>0.876469</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916309</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>0.392463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <td>0.756981</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.165649</td>\n",
       "      <td>0.260270</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.916309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465123</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>0.421012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.167878</td>\n",
       "      <td>0.481134</td>\n",
       "      <td>0.423606</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.465123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223738</td>\n",
       "      <td>0.796284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>0.021337</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.019903</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>0.223738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.411429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.391743</td>\n",
       "      <td>0.184482</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.160902</td>\n",
       "      <td>0.439256</td>\n",
       "      <td>0.383781</td>\n",
       "      <td>0.392463</td>\n",
       "      <td>0.421012</td>\n",
       "      <td>0.796284</td>\n",
       "      <td>-0.411429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       jaccard_index  anchor ⊂ target  target ⊂ anchor  \\\n",
       "jaccard_index               1.000000         0.359760         0.249074   \n",
       "anchor ⊂ target             0.359760         1.000000        -0.047205   \n",
       "target ⊂ anchor             0.249074        -0.047205         1.000000   \n",
       "number_of_words             0.275053         0.180084        -0.228518   \n",
       "fuzz_ratio                  0.739894         0.281142         0.163665   \n",
       "fuzz_partial_ratio          0.727435         0.406478         0.372660   \n",
       "fuzz_token_set_ratio        0.857627         0.360223         0.321515   \n",
       "fuzz_token_sort_ratio       0.756981         0.283221         0.165649   \n",
       "pred                        0.433071         0.194873         0.122449   \n",
       "bias                        0.021337        -0.003619         0.014098   \n",
       "score                       0.391743         0.184482         0.105758   \n",
       "\n",
       "                       number_of_words  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "jaccard_index                 0.275053    0.739894            0.727435   \n",
       "anchor ⊂ target               0.180084    0.281142            0.406478   \n",
       "target ⊂ anchor              -0.228518    0.163665            0.372660   \n",
       "number_of_words               1.000000    0.252689            0.171080   \n",
       "fuzz_ratio                    0.252689    1.000000            0.867131   \n",
       "fuzz_partial_ratio            0.171080    0.867131            1.000000   \n",
       "fuzz_token_set_ratio          0.255549    0.876469            0.887268   \n",
       "fuzz_token_sort_ratio         0.260270    0.899480            0.813278   \n",
       "pred                          0.167878    0.481134            0.423606   \n",
       "bias                         -0.006302    0.017200            0.019903   \n",
       "score                         0.160902    0.439256            0.383781   \n",
       "\n",
       "                       fuzz_token_set_ratio  fuzz_token_sort_ratio      pred  \\\n",
       "jaccard_index                      0.857627               0.756981  0.433071   \n",
       "anchor ⊂ target                    0.360223               0.283221  0.194873   \n",
       "target ⊂ anchor                    0.321515               0.165649  0.122449   \n",
       "number_of_words                    0.255549               0.260270  0.167878   \n",
       "fuzz_ratio                         0.876469               0.899480  0.481134   \n",
       "fuzz_partial_ratio                 0.887268               0.813278  0.423606   \n",
       "fuzz_token_set_ratio               1.000000               0.916309  0.437732   \n",
       "fuzz_token_sort_ratio              0.916309               1.000000  0.465123   \n",
       "pred                               0.437732               0.465123  1.000000   \n",
       "bias                               0.027199               0.022471  0.223738   \n",
       "score                              0.392463               0.421012  0.796284   \n",
       "\n",
       "                           bias     score  \n",
       "jaccard_index          0.021337  0.391743  \n",
       "anchor ⊂ target       -0.003619  0.184482  \n",
       "target ⊂ anchor        0.014098  0.105758  \n",
       "number_of_words       -0.006302  0.160902  \n",
       "fuzz_ratio             0.017200  0.439256  \n",
       "fuzz_partial_ratio     0.019903  0.383781  \n",
       "fuzz_token_set_ratio   0.027199  0.392463  \n",
       "fuzz_token_sort_ratio  0.022471  0.421012  \n",
       "pred                   0.223738  0.796284  \n",
       "bias                   1.000000 -0.411429  \n",
       "score                 -0.411429  1.000000  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df1 = pd.get_dummies(df[\"context_grp_1\"], prefix='context_grp_1')\n",
    "sub_df2 = pd.get_dummies(df[\"text_grp_1\"], prefix='text_grp_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_grp_1_A</th>\n",
       "      <th>context_grp_1_B</th>\n",
       "      <th>context_grp_1_C</th>\n",
       "      <th>context_grp_1_D</th>\n",
       "      <th>context_grp_1_E</th>\n",
       "      <th>context_grp_1_F</th>\n",
       "      <th>context_grp_1_G</th>\n",
       "      <th>context_grp_1_H</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>anchor ⊂ target</th>\n",
       "      <th>target ⊂ anchor</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context_grp_1_A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.188769</td>\n",
       "      <td>-0.146425</td>\n",
       "      <td>-0.067786</td>\n",
       "      <td>-0.074431</td>\n",
       "      <td>-0.125743</td>\n",
       "      <td>-0.157988</td>\n",
       "      <td>-0.160842</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.016188</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>-0.012636</td>\n",
       "      <td>-0.016906</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_B</th>\n",
       "      <td>-0.188769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.218606</td>\n",
       "      <td>-0.101202</td>\n",
       "      <td>-0.111123</td>\n",
       "      <td>-0.187729</td>\n",
       "      <td>-0.235868</td>\n",
       "      <td>-0.240129</td>\n",
       "      <td>0.074618</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.058659</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.054574</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.033986</td>\n",
       "      <td>-0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_C</th>\n",
       "      <td>-0.146425</td>\n",
       "      <td>-0.218606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.078501</td>\n",
       "      <td>-0.086196</td>\n",
       "      <td>-0.145618</td>\n",
       "      <td>-0.182959</td>\n",
       "      <td>-0.186264</td>\n",
       "      <td>-0.079814</td>\n",
       "      <td>-0.025960</td>\n",
       "      <td>-0.000922</td>\n",
       "      <td>-0.042738</td>\n",
       "      <td>-0.064396</td>\n",
       "      <td>-0.059950</td>\n",
       "      <td>-0.078960</td>\n",
       "      <td>-0.071993</td>\n",
       "      <td>-0.042650</td>\n",
       "      <td>-0.041700</td>\n",
       "      <td>0.002925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_D</th>\n",
       "      <td>-0.067786</td>\n",
       "      <td>-0.101202</td>\n",
       "      <td>-0.078501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039904</td>\n",
       "      <td>-0.067413</td>\n",
       "      <td>-0.084700</td>\n",
       "      <td>-0.086230</td>\n",
       "      <td>-0.009963</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>-0.064728</td>\n",
       "      <td>-0.003162</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>-0.004467</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.020839</td>\n",
       "      <td>-0.017065</td>\n",
       "      <td>-0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_E</th>\n",
       "      <td>-0.074431</td>\n",
       "      <td>-0.111123</td>\n",
       "      <td>-0.086196</td>\n",
       "      <td>-0.039904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074021</td>\n",
       "      <td>-0.093002</td>\n",
       "      <td>-0.094683</td>\n",
       "      <td>-0.008614</td>\n",
       "      <td>-0.013285</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>-0.019049</td>\n",
       "      <td>-0.029503</td>\n",
       "      <td>-0.025020</td>\n",
       "      <td>-0.023259</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>-0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_F</th>\n",
       "      <td>-0.125743</td>\n",
       "      <td>-0.187729</td>\n",
       "      <td>-0.145618</td>\n",
       "      <td>-0.067413</td>\n",
       "      <td>-0.074021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.157117</td>\n",
       "      <td>-0.159955</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_G</th>\n",
       "      <td>-0.157988</td>\n",
       "      <td>-0.235868</td>\n",
       "      <td>-0.182959</td>\n",
       "      <td>-0.084700</td>\n",
       "      <td>-0.093002</td>\n",
       "      <td>-0.157117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200973</td>\n",
       "      <td>-0.029026</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.030389</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>-0.023732</td>\n",
       "      <td>-0.029187</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>-0.007579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_grp_1_H</th>\n",
       "      <td>-0.160842</td>\n",
       "      <td>-0.240129</td>\n",
       "      <td>-0.186264</td>\n",
       "      <td>-0.086230</td>\n",
       "      <td>-0.094683</td>\n",
       "      <td>-0.159955</td>\n",
       "      <td>-0.200973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>-0.010980</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.032140</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>-0.009815</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_index</th>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.074618</td>\n",
       "      <td>-0.079814</td>\n",
       "      <td>-0.009963</td>\n",
       "      <td>-0.008614</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>-0.029026</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359760</td>\n",
       "      <td>0.249074</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.727435</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.756981</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.391743</td>\n",
       "      <td>0.021337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor ⊂ target</th>\n",
       "      <td>0.011481</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>-0.025960</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>-0.013285</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.359760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047205</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>0.406478</td>\n",
       "      <td>0.360223</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>0.184482</td>\n",
       "      <td>-0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target ⊂ anchor</th>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-0.000922</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-0.010980</td>\n",
       "      <td>0.249074</td>\n",
       "      <td>-0.047205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.228518</td>\n",
       "      <td>0.163665</td>\n",
       "      <td>0.372660</td>\n",
       "      <td>0.321515</td>\n",
       "      <td>0.165649</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.014098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_words</th>\n",
       "      <td>-0.017571</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>-0.042738</td>\n",
       "      <td>-0.064728</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>0.180084</td>\n",
       "      <td>-0.228518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>0.171080</td>\n",
       "      <td>0.255549</td>\n",
       "      <td>0.260270</td>\n",
       "      <td>0.167878</td>\n",
       "      <td>0.160902</td>\n",
       "      <td>-0.006302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.058659</td>\n",
       "      <td>-0.064396</td>\n",
       "      <td>-0.003162</td>\n",
       "      <td>-0.019049</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>-0.030389</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>0.163665</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>0.876469</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.481134</td>\n",
       "      <td>0.439256</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>-0.059950</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>-0.029503</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>-0.010228</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>0.727435</td>\n",
       "      <td>0.406478</td>\n",
       "      <td>0.372660</td>\n",
       "      <td>0.171080</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.423606</td>\n",
       "      <td>0.383781</td>\n",
       "      <td>0.019903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <td>0.016188</td>\n",
       "      <td>0.054574</td>\n",
       "      <td>-0.078960</td>\n",
       "      <td>-0.004467</td>\n",
       "      <td>-0.025020</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>-0.023732</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.360223</td>\n",
       "      <td>0.321515</td>\n",
       "      <td>0.255549</td>\n",
       "      <td>0.876469</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916309</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.392463</td>\n",
       "      <td>0.027199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>-0.071993</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.023259</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>-0.029187</td>\n",
       "      <td>0.032140</td>\n",
       "      <td>0.756981</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.165649</td>\n",
       "      <td>0.260270</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.916309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465123</td>\n",
       "      <td>0.421012</td>\n",
       "      <td>0.022471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>-0.012636</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>-0.042650</td>\n",
       "      <td>-0.020839</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.167878</td>\n",
       "      <td>0.481134</td>\n",
       "      <td>0.423606</td>\n",
       "      <td>0.437732</td>\n",
       "      <td>0.465123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796284</td>\n",
       "      <td>0.223738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>-0.016906</td>\n",
       "      <td>0.033986</td>\n",
       "      <td>-0.041700</td>\n",
       "      <td>-0.017065</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>-0.009815</td>\n",
       "      <td>0.391743</td>\n",
       "      <td>0.184482</td>\n",
       "      <td>0.105758</td>\n",
       "      <td>0.160902</td>\n",
       "      <td>0.439256</td>\n",
       "      <td>0.383781</td>\n",
       "      <td>0.392463</td>\n",
       "      <td>0.421012</td>\n",
       "      <td>0.796284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.411429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>0.008200</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>-0.003902</td>\n",
       "      <td>-0.003562</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>-0.007579</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.019903</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>0.223738</td>\n",
       "      <td>-0.411429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       context_grp_1_A  context_grp_1_B  context_grp_1_C  \\\n",
       "context_grp_1_A               1.000000        -0.188769        -0.146425   \n",
       "context_grp_1_B              -0.188769         1.000000        -0.218606   \n",
       "context_grp_1_C              -0.146425        -0.218606         1.000000   \n",
       "context_grp_1_D              -0.067786        -0.101202        -0.078501   \n",
       "context_grp_1_E              -0.074431        -0.111123        -0.086196   \n",
       "context_grp_1_F              -0.125743        -0.187729        -0.145618   \n",
       "context_grp_1_G              -0.157988        -0.235868        -0.182959   \n",
       "context_grp_1_H              -0.160842        -0.240129        -0.186264   \n",
       "jaccard_index                 0.001514         0.074618        -0.079814   \n",
       "anchor ⊂ target               0.011481        -0.004194        -0.025960   \n",
       "target ⊂ anchor               0.003558         0.004432        -0.000922   \n",
       "number_of_words              -0.017571         0.053312        -0.042738   \n",
       "fuzz_ratio                    0.008811         0.058659        -0.064396   \n",
       "fuzz_partial_ratio            0.012629         0.035556        -0.059950   \n",
       "fuzz_token_set_ratio          0.016188         0.054574        -0.078960   \n",
       "fuzz_token_sort_ratio         0.011961         0.060034        -0.071993   \n",
       "pred                         -0.012636         0.035332        -0.042650   \n",
       "score                        -0.016906         0.033986        -0.041700   \n",
       "bias                          0.008200        -0.001524         0.002925   \n",
       "\n",
       "                       context_grp_1_D  context_grp_1_E  context_grp_1_F  \\\n",
       "context_grp_1_A              -0.067786        -0.074431        -0.125743   \n",
       "context_grp_1_B              -0.101202        -0.111123        -0.187729   \n",
       "context_grp_1_C              -0.078501        -0.086196        -0.145618   \n",
       "context_grp_1_D               1.000000        -0.039904        -0.067413   \n",
       "context_grp_1_E              -0.039904         1.000000        -0.074021   \n",
       "context_grp_1_F              -0.067413        -0.074021         1.000000   \n",
       "context_grp_1_G              -0.084700        -0.093002        -0.157117   \n",
       "context_grp_1_H              -0.086230        -0.094683        -0.159955   \n",
       "jaccard_index                -0.009963        -0.008614         0.011075   \n",
       "anchor ⊂ target               0.003018        -0.013285         0.009493   \n",
       "target ⊂ anchor               0.011917        -0.004464         0.001675   \n",
       "number_of_words              -0.064728        -0.011442         0.000100   \n",
       "fuzz_ratio                   -0.003162        -0.019049         0.004521   \n",
       "fuzz_partial_ratio            0.005025        -0.029503         0.005691   \n",
       "fuzz_token_set_ratio         -0.004467        -0.025020         0.005389   \n",
       "fuzz_token_sort_ratio        -0.001521        -0.023259         0.001316   \n",
       "pred                         -0.020839         0.004672         0.014183   \n",
       "score                        -0.017065         0.006580         0.012307   \n",
       "bias                         -0.003902        -0.003562         0.001540   \n",
       "\n",
       "                       context_grp_1_G  context_grp_1_H  jaccard_index  \\\n",
       "context_grp_1_A              -0.157988        -0.160842       0.001514   \n",
       "context_grp_1_B              -0.235868        -0.240129       0.074618   \n",
       "context_grp_1_C              -0.182959        -0.186264      -0.079814   \n",
       "context_grp_1_D              -0.084700        -0.086230      -0.009963   \n",
       "context_grp_1_E              -0.093002        -0.094683      -0.008614   \n",
       "context_grp_1_F              -0.157117        -0.159955       0.011075   \n",
       "context_grp_1_G               1.000000        -0.200973      -0.029026   \n",
       "context_grp_1_H              -0.200973         1.000000       0.020159   \n",
       "jaccard_index                -0.029026         0.020159       1.000000   \n",
       "anchor ⊂ target               0.013887         0.003263       0.359760   \n",
       "target ⊂ anchor              -0.000903        -0.010980       0.249074   \n",
       "number_of_words              -0.003774         0.037509       0.275053   \n",
       "fuzz_ratio                   -0.030389         0.026243       0.739894   \n",
       "fuzz_partial_ratio           -0.010228         0.025017       0.727435   \n",
       "fuzz_token_set_ratio         -0.023732         0.034726       0.857627   \n",
       "fuzz_token_sort_ratio        -0.029187         0.032140       0.756981   \n",
       "pred                          0.016814        -0.009129       0.433071   \n",
       "score                         0.020428        -0.009815       0.391743   \n",
       "bias                         -0.007579         0.002059       0.021337   \n",
       "\n",
       "                       anchor ⊂ target  target ⊂ anchor  number_of_words  \\\n",
       "context_grp_1_A               0.011481         0.003558        -0.017571   \n",
       "context_grp_1_B              -0.004194         0.004432         0.053312   \n",
       "context_grp_1_C              -0.025960        -0.000922        -0.042738   \n",
       "context_grp_1_D               0.003018         0.011917        -0.064728   \n",
       "context_grp_1_E              -0.013285        -0.004464        -0.011442   \n",
       "context_grp_1_F               0.009493         0.001675         0.000100   \n",
       "context_grp_1_G               0.013887        -0.000903        -0.003774   \n",
       "context_grp_1_H               0.003263        -0.010980         0.037509   \n",
       "jaccard_index                 0.359760         0.249074         0.275053   \n",
       "anchor ⊂ target               1.000000        -0.047205         0.180084   \n",
       "target ⊂ anchor              -0.047205         1.000000        -0.228518   \n",
       "number_of_words               0.180084        -0.228518         1.000000   \n",
       "fuzz_ratio                    0.281142         0.163665         0.252689   \n",
       "fuzz_partial_ratio            0.406478         0.372660         0.171080   \n",
       "fuzz_token_set_ratio          0.360223         0.321515         0.255549   \n",
       "fuzz_token_sort_ratio         0.283221         0.165649         0.260270   \n",
       "pred                          0.194873         0.122449         0.167878   \n",
       "score                         0.184482         0.105758         0.160902   \n",
       "bias                         -0.003619         0.014098        -0.006302   \n",
       "\n",
       "                       fuzz_ratio  fuzz_partial_ratio  fuzz_token_set_ratio  \\\n",
       "context_grp_1_A          0.008811            0.012629              0.016188   \n",
       "context_grp_1_B          0.058659            0.035556              0.054574   \n",
       "context_grp_1_C         -0.064396           -0.059950             -0.078960   \n",
       "context_grp_1_D         -0.003162            0.005025             -0.004467   \n",
       "context_grp_1_E         -0.019049           -0.029503             -0.025020   \n",
       "context_grp_1_F          0.004521            0.005691              0.005389   \n",
       "context_grp_1_G         -0.030389           -0.010228             -0.023732   \n",
       "context_grp_1_H          0.026243            0.025017              0.034726   \n",
       "jaccard_index            0.739894            0.727435              0.857627   \n",
       "anchor ⊂ target          0.281142            0.406478              0.360223   \n",
       "target ⊂ anchor          0.163665            0.372660              0.321515   \n",
       "number_of_words          0.252689            0.171080              0.255549   \n",
       "fuzz_ratio               1.000000            0.867131              0.876469   \n",
       "fuzz_partial_ratio       0.867131            1.000000              0.887268   \n",
       "fuzz_token_set_ratio     0.876469            0.887268              1.000000   \n",
       "fuzz_token_sort_ratio    0.899480            0.813278              0.916309   \n",
       "pred                     0.481134            0.423606              0.437732   \n",
       "score                    0.439256            0.383781              0.392463   \n",
       "bias                     0.017200            0.019903              0.027199   \n",
       "\n",
       "                       fuzz_token_sort_ratio      pred     score      bias  \n",
       "context_grp_1_A                     0.011961 -0.012636 -0.016906  0.008200  \n",
       "context_grp_1_B                     0.060034  0.035332  0.033986 -0.001524  \n",
       "context_grp_1_C                    -0.071993 -0.042650 -0.041700  0.002925  \n",
       "context_grp_1_D                    -0.001521 -0.020839 -0.017065 -0.003902  \n",
       "context_grp_1_E                    -0.023259  0.004672  0.006580 -0.003562  \n",
       "context_grp_1_F                     0.001316  0.014183  0.012307  0.001540  \n",
       "context_grp_1_G                    -0.029187  0.016814  0.020428 -0.007579  \n",
       "context_grp_1_H                     0.032140 -0.009129 -0.009815  0.002059  \n",
       "jaccard_index                       0.756981  0.433071  0.391743  0.021337  \n",
       "anchor ⊂ target                     0.283221  0.194873  0.184482 -0.003619  \n",
       "target ⊂ anchor                     0.165649  0.122449  0.105758  0.014098  \n",
       "number_of_words                     0.260270  0.167878  0.160902 -0.006302  \n",
       "fuzz_ratio                          0.899480  0.481134  0.439256  0.017200  \n",
       "fuzz_partial_ratio                  0.813278  0.423606  0.383781  0.019903  \n",
       "fuzz_token_set_ratio                0.916309  0.437732  0.392463  0.027199  \n",
       "fuzz_token_sort_ratio               1.000000  0.465123  0.421012  0.022471  \n",
       "pred                                0.465123  1.000000  0.796284  0.223738  \n",
       "score                               0.421012  0.796284  1.000000 -0.411429  \n",
       "bias                                0.022471  0.223738 -0.411429  1.000000  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([sub_df1, df[[\"jaccard_index\", \"anchor ⊂ target\", \"target ⊂ anchor\", \"number_of_words\",\n",
    "    \"fuzz_ratio\", \"fuzz_partial_ratio\", \"fuzz_token_set_ratio\", \"fuzz_token_sort_ratio\", \"pred\", \"score\", \"bias\"]]], axis=1)\n",
    "\n",
    "#df2 = pd.concat([sub_df1, df[[\"anchor ⊂ target\", \"target ⊂ anchor\", \n",
    "#     \"pred\", \"bias\"]]], axis=1)\n",
    "df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = df2.drop(columns=[\"bias\", \"score\"])\n",
    "Y = df2[[\"bias\", \"pred\", \"score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "#from sklearn.feature_selection import chi2\n",
    "#from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi2_selector = SelectKBest(chi2, k=10)\n",
    "#X_kbest = chi2_selector.transform(X)\n",
    "#chi2(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=25, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['context_grp_1_A', 'context_grp_1_B', 'context_grp_1_C',\n",
       "       'context_grp_1_D', 'context_grp_1_E', 'context_grp_1_F',\n",
       "       'context_grp_1_G', 'context_grp_1_H', 'jaccard_index',\n",
       "       'anchor ⊂ target', 'target ⊂ anchor', 'number_of_words', 'fuzz_ratio',\n",
       "       'fuzz_partial_ratio', 'fuzz_token_set_ratio', 'fuzz_token_sort_ratio',\n",
       "       'pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29739</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15955</th>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>-0.249896</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33065</th>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.510470</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.282720</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bias      pred  score\n",
       "29739  0.000067  0.000067   0.00\n",
       "15955  0.008850  0.258850   0.25\n",
       "26299 -0.249896  0.000104   0.25\n",
       "33065  0.010470  0.510470   0.50\n",
       "1564   0.032720  0.282720   0.25"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = RandomForestRegressor(max_depth=8, min_samples_leaf=2, random_state=75)\n",
    "#model = LinearRegression()\n",
    "#model = LinearSVR()\n",
    "#model = xgb.XGBRegressor(max_depth=3)\n",
    "#model = RidgeCV()\n",
    "#model = SVR()\n",
    "#model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "#cv_results = cross_validate(model, X, Y[[\"bias\"]], cv=5,\n",
    "#                         scoring=('r2', 'neg_mean_squared_error'),\n",
    "#                         return_train_score=True)\n",
    "\n",
    "#cv_results = cross_val_predict(model, X, Y[[\"bias\"]], cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansontang/miniconda3_new/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=8, min_samples_leaf=2, random_state=75)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train[[\"bias\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00698331, 0.00796222, 0.00779119, 0.00450102, 0.00220451,\n",
       "       0.00302137, 0.0118788 , 0.00710616, 0.03910988, 0.00181466,\n",
       "       0.00084614, 0.03294371, 0.09451328, 0.06623636, 0.08230422,\n",
       "       0.08564461, 0.54513857])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['context_grp_1_A', 'context_grp_1_B', 'context_grp_1_C',\n",
       "       'context_grp_1_D', 'context_grp_1_E', 'context_grp_1_F',\n",
       "       'context_grp_1_G', 'context_grp_1_H', 'jaccard_index',\n",
       "       'anchor ⊂ target', 'target ⊂ anchor', 'number_of_words',\n",
       "       'fuzz_ratio', 'fuzz_partial_ratio', 'fuzz_token_set_ratio',\n",
       "       'fuzz_token_sort_ratio', 'pred'], dtype=object)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03040598,  0.02384845, -0.00481857, ...,  0.0155117 ,\n",
       "       -0.05162446, -0.00348773])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_estimated</th>\n",
       "      <td>0.318244</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bias  bias_estimated\n",
       "bias            1.000000        0.318244\n",
       "bias_estimated  0.318244        1.000000"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[\"bias_estimated\"] = y_pred\n",
    "y_test[[\"bias\", \"bias_estimated\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ac192683198>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test[[\"bias\"]].sort_values(\"bias\").reset_index(drop=True).plot()\n",
    "y_test[[\"bias_estimated\"]].sort_values(\"bias_estimated\").reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ac19520f908>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(y_test[\"bias_estimated\"] - y_test[\"bias\"]).sort_values().reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>bias_estimated</th>\n",
       "      <th>pred_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11465</th>\n",
       "      <td>-0.156479</td>\n",
       "      <td>0.593521</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.030406</td>\n",
       "      <td>0.563115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>0.046777</td>\n",
       "      <td>0.546777</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.522929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33535</th>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.266416</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.004819</td>\n",
       "      <td>0.271235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21212</th>\n",
       "      <td>-0.271750</td>\n",
       "      <td>0.478250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.472881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>-0.069818</td>\n",
       "      <td>0.430182</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.001386</td>\n",
       "      <td>0.431568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bias      pred  score  bias_estimated  pred_corrected\n",
       "11465 -0.156479  0.593521   0.75        0.030406        0.563115\n",
       "5870   0.046777  0.546777   0.50        0.023848        0.522929\n",
       "33535  0.016416  0.266416   0.25       -0.004819        0.271235\n",
       "21212 -0.271750  0.478250   0.75        0.005369        0.472881\n",
       "13114 -0.069818  0.430182   0.50       -0.001386        0.431568"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[\"pred_corrected\"] = y_test[\"pred\"] - y_test[\"bias_estimated\"]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798448</td>\n",
       "      <td>0.811006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>0.798448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_corrected</th>\n",
       "      <td>0.811006</td>\n",
       "      <td>0.983336</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   score      pred  pred_corrected\n",
       "score           1.000000  0.798448        0.811006\n",
       "pred            0.798448  1.000000        0.983336\n",
       "pred_corrected  0.811006  0.983336        1.000000"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[[\"score\", \"pred\", \"pred_corrected\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>bias_estimated</th>\n",
       "      <th>pred_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18624</th>\n",
       "      <td>-0.938692</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.485183</td>\n",
       "      <td>0.546491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>-0.499253</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.437325</td>\n",
       "      <td>0.438072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.425292</td>\n",
       "      <td>0.426744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28658</th>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.403958</td>\n",
       "      <td>0.406535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17806</th>\n",
       "      <td>-0.184329</td>\n",
       "      <td>0.065671</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.392321</td>\n",
       "      <td>0.457992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23841</th>\n",
       "      <td>-0.146693</td>\n",
       "      <td>0.103307</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.379699</td>\n",
       "      <td>0.483006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>-0.389340</td>\n",
       "      <td>0.110660</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.353040</td>\n",
       "      <td>0.463700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28847</th>\n",
       "      <td>-0.658183</td>\n",
       "      <td>0.091817</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.352958</td>\n",
       "      <td>0.444775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>-0.470894</td>\n",
       "      <td>0.029106</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.342803</td>\n",
       "      <td>0.371909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>-0.716644</td>\n",
       "      <td>0.033356</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.336374</td>\n",
       "      <td>0.369730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.329638</td>\n",
       "      <td>0.333435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.329122</td>\n",
       "      <td>0.387801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18807</th>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.327698</td>\n",
       "      <td>0.330054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24853</th>\n",
       "      <td>-0.715157</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.320899</td>\n",
       "      <td>0.355741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.313619</td>\n",
       "      <td>0.314144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.302353</td>\n",
       "      <td>0.302382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.300805</td>\n",
       "      <td>0.301617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36290</th>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.300179</td>\n",
       "      <td>0.300296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>-0.385779</td>\n",
       "      <td>0.114221</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.293638</td>\n",
       "      <td>0.407859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.288661</td>\n",
       "      <td>0.288727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34580</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.284545</td>\n",
       "      <td>0.284852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.282678</td>\n",
       "      <td>0.284313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22429</th>\n",
       "      <td>0.060120</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.274078</td>\n",
       "      <td>0.334198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>-0.249922</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.269703</td>\n",
       "      <td>0.269781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>-0.134760</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.268465</td>\n",
       "      <td>0.383705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20424</th>\n",
       "      <td>0.014681</td>\n",
       "      <td>0.014681</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.267594</td>\n",
       "      <td>0.282275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>-0.240890</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.254332</td>\n",
       "      <td>0.263442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.251229</td>\n",
       "      <td>0.254599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.244632</td>\n",
       "      <td>0.244735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>-0.667726</td>\n",
       "      <td>0.082274</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.241471</td>\n",
       "      <td>0.323745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bias      pred  score  bias_estimated  pred_corrected\n",
       "18624 -0.938692  0.061308   1.00       -0.485183        0.546491\n",
       "6129  -0.499253  0.000747   0.50       -0.437325        0.438072\n",
       "5      0.001452  0.001452   0.00       -0.425292        0.426744\n",
       "28658  0.002577  0.002577   0.00       -0.403958        0.406535\n",
       "17806 -0.184329  0.065671   0.25       -0.392321        0.457992\n",
       "23841 -0.146693  0.103307   0.25       -0.379699        0.483006\n",
       "5770  -0.389340  0.110660   0.50       -0.353040        0.463700\n",
       "28847 -0.658183  0.091817   0.75       -0.352958        0.444775\n",
       "8768  -0.470894  0.029106   0.50       -0.342803        0.371909\n",
       "3336  -0.716644  0.033356   0.75       -0.336374        0.369730\n",
       "5903   0.003797  0.003797   0.00       -0.329638        0.333435\n",
       "5245   0.058678  0.058678   0.00       -0.329122        0.387801\n",
       "18807  0.002356  0.002356   0.00       -0.327698        0.330054\n",
       "24853 -0.715157  0.034843   0.75       -0.320899        0.355741\n",
       "4      0.000525  0.000525   0.00       -0.313619        0.314144\n",
       "22498  0.000030  0.000030   0.00       -0.302353        0.302382\n",
       "10951  0.000812  0.000812   0.00       -0.300805        0.301617\n",
       "36290  0.000118  0.000118   0.00       -0.300179        0.300296\n",
       "15071 -0.385779  0.114221   0.50       -0.293638        0.407859\n",
       "6905   0.000067  0.000067   0.00       -0.288661        0.288727\n",
       "34580  0.000307  0.000307   0.00       -0.284545        0.284852\n",
       "1982   0.001635  0.001635   0.00       -0.282678        0.284313\n",
       "22429  0.060120  0.060120   0.00       -0.274078        0.334198\n",
       "1125  -0.249922  0.000078   0.25       -0.269703        0.269781\n",
       "5295  -0.134760  0.115240   0.25       -0.268465        0.383705\n",
       "20424  0.014681  0.014681   0.00       -0.267594        0.282275\n",
       "7503  -0.240890  0.009110   0.25       -0.254332        0.263442\n",
       "1769   0.003370  0.003370   0.00       -0.251229        0.254599\n",
       "11946  0.000103  0.000103   0.00       -0.244632        0.244735\n",
       "5354  -0.667726  0.082274   0.75       -0.241471        0.323745"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sort_values(\"bias_estimated\").head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "      <th>bias_estimated</th>\n",
       "      <th>pred_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>0.249237</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.760674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17248</th>\n",
       "      <td>-0.002449</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.213241</td>\n",
       "      <td>0.784311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21570</th>\n",
       "      <td>-0.029137</td>\n",
       "      <td>0.970863</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.210445</td>\n",
       "      <td>0.760418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16915</th>\n",
       "      <td>-0.057882</td>\n",
       "      <td>0.942118</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.205485</td>\n",
       "      <td>0.736633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10933</th>\n",
       "      <td>0.248585</td>\n",
       "      <td>0.998585</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.203762</td>\n",
       "      <td>0.794823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19369</th>\n",
       "      <td>0.244306</td>\n",
       "      <td>0.994306</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.203115</td>\n",
       "      <td>0.791191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>-0.001019</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.200311</td>\n",
       "      <td>0.798670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25593</th>\n",
       "      <td>0.165941</td>\n",
       "      <td>0.915941</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.199711</td>\n",
       "      <td>0.716230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>0.499157</td>\n",
       "      <td>0.999157</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.195732</td>\n",
       "      <td>0.803425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>0.498266</td>\n",
       "      <td>0.998266</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>0.802710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.248549</td>\n",
       "      <td>0.998549</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.195197</td>\n",
       "      <td>0.803352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22963</th>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.190528</td>\n",
       "      <td>0.808820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>0.498488</td>\n",
       "      <td>0.998488</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.185545</td>\n",
       "      <td>0.812943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.999144</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.179022</td>\n",
       "      <td>0.820122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>0.597798</td>\n",
       "      <td>0.847798</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.170057</td>\n",
       "      <td>0.677742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34073</th>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.830342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>-0.000842</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.167197</td>\n",
       "      <td>0.831961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16522</th>\n",
       "      <td>0.426579</td>\n",
       "      <td>0.926579</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.166514</td>\n",
       "      <td>0.760064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18558</th>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.164805</td>\n",
       "      <td>0.834934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>0.174144</td>\n",
       "      <td>0.924144</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.164639</td>\n",
       "      <td>0.759504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28281</th>\n",
       "      <td>0.249440</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.164551</td>\n",
       "      <td>0.834890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22340</th>\n",
       "      <td>0.249690</td>\n",
       "      <td>0.999690</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.160421</td>\n",
       "      <td>0.839269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>0.193646</td>\n",
       "      <td>0.943646</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.159347</td>\n",
       "      <td>0.784299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>0.198948</td>\n",
       "      <td>0.948948</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.157323</td>\n",
       "      <td>0.791625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>-0.033311</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.156376</td>\n",
       "      <td>0.810312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>-0.000579</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.155375</td>\n",
       "      <td>0.844045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22618</th>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.997735</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>0.842461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34206</th>\n",
       "      <td>0.139980</td>\n",
       "      <td>0.889980</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.154950</td>\n",
       "      <td>0.735030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16822</th>\n",
       "      <td>0.238356</td>\n",
       "      <td>0.988356</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.154233</td>\n",
       "      <td>0.834123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25187</th>\n",
       "      <td>-0.000287</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.153944</td>\n",
       "      <td>0.845768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bias      pred  score  bias_estimated  pred_corrected\n",
       "9277   0.249237  0.999237   0.75        0.238564        0.760674\n",
       "17248 -0.002449  0.997551   1.00        0.213241        0.784311\n",
       "21570 -0.029137  0.970863   1.00        0.210445        0.760418\n",
       "16915 -0.057882  0.942118   1.00        0.205485        0.736633\n",
       "10933  0.248585  0.998585   0.75        0.203762        0.794823\n",
       "19369  0.244306  0.994306   0.75        0.203115        0.791191\n",
       "7143  -0.001019  0.998981   1.00        0.200311        0.798670\n",
       "25593  0.165941  0.915941   0.75        0.199711        0.716230\n",
       "14345  0.499157  0.999157   0.50        0.195732        0.803425\n",
       "4783   0.498266  0.998266   0.50        0.195556        0.802710\n",
       "887    0.248549  0.998549   0.75        0.195197        0.803352\n",
       "22963  0.499348  0.999348   0.50        0.190528        0.808820\n",
       "1691   0.498488  0.998488   0.50        0.185545        0.812943\n",
       "9286   0.249144  0.999144   0.75        0.179022        0.820122\n",
       "10438  0.597798  0.847798   0.25        0.170057        0.677742\n",
       "34073 -0.000427  0.999573   1.00        0.169231        0.830342\n",
       "724   -0.000842  0.999158   1.00        0.167197        0.831961\n",
       "16522  0.426579  0.926579   0.50        0.166514        0.760064\n",
       "18558 -0.000261  0.999739   1.00        0.164805        0.834934\n",
       "14518  0.174144  0.924144   0.75        0.164639        0.759504\n",
       "28281  0.249440  0.999440   0.75        0.164551        0.834890\n",
       "22340  0.249690  0.999690   0.75        0.160421        0.839269\n",
       "2207   0.193646  0.943646   0.75        0.159347        0.784299\n",
       "25075  0.198948  0.948948   0.75        0.157323        0.791625\n",
       "8790  -0.033311  0.966689   1.00        0.156376        0.810312\n",
       "9306  -0.000579  0.999421   1.00        0.155375        0.844045\n",
       "22618 -0.002265  0.997735   1.00        0.155274        0.842461\n",
       "34206  0.139980  0.889980   0.75        0.154950        0.735030\n",
       "16822  0.238356  0.988356   0.75        0.154233        0.834123\n",
       "25187 -0.000287  0.999713   1.00        0.153944        0.845768"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sort_values(\"bias_estimated\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "export_graphviz(estimator, \n",
    "                out_file='tree.dot', \n",
    "                feature_names = model.feature_names_in_,\n",
    "                class_names = \"bias_estimated\",\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "#Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
